ğŸ§  Introduction:

    + This project builds an AI system to detect spam accounts on Reddit based on user and post data.
    The goal is to classify Reddit accounts as "normal" or "spam" using statistical features (karma, account age, posting frequency, etc.) and machine learning models.


ğŸš€ Features:

    + ğŸ§© Collect user and post data from the Reddit API (Automaticly).

    + ğŸ§® Data preprocessing and cleaning (remove duplicates, normalize values).

    + ğŸ¤– Train Machine Learning models to detect spam accounts.

    + ğŸ“Š Visualize data and classification results.

    + â˜ï¸ Automatic periodic updates and data storage using GitHub Actions.


ğŸ—‚ï¸ Project Structure:


```

â”œâ”€â”€ ğŸ“ .github
â”‚   â””â”€â”€ ğŸ“ workflows
â”‚       â””â”€â”€ âš™ï¸ auto.yml
â”œâ”€â”€ ğŸ“ crawReditRender
â”‚   â”œâ”€â”€ ğŸ“ data
â”‚   â”‚   â””â”€â”€ âš™ï¸ .gitkeep
â”‚   â”œâ”€â”€ ğŸ“ README.md
â”‚   â”œâ”€â”€ ğŸ app.py
â”‚   â”œâ”€â”€ ğŸ reddit_crawler.py
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“ data_prepare
â”‚   â”œâ”€â”€ ğŸ“ Huy
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ heat_map_activate_comment.png
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ heat_map_activate_post.png
â”‚   â”‚   â”œâ”€â”€ ğŸ heatmap_activate_week_post_comment.py.py
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ scatter_post_link_karma.png
â”‚   â”‚   â””â”€â”€ ğŸ scratter_postScore_karma.py.py
â”‚   â”œâ”€â”€ ğŸ“ Kiet
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ Figure_1.png
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ Figure_2.png
â”‚   â”‚   â”œâ”€â”€ ğŸ Verified_and_Premium_rate.py
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ account_created_chart.py
â”‚   â”œâ”€â”€ ğŸ“ Trung
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ Figure_1.png
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ Figure_2.png
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ Figure_3.png
â”‚   â”‚   â””â”€â”€ ğŸ Lab.py
â”‚   â”œâ”€â”€ ğŸ“ Vinh
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ correlation_comment_and_post_karma.py
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ distribute_comment_duplicate_score.png
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ distribute_post_duplicate_score.png
â”‚   â”‚   â”œâ”€â”€ ğŸ duplicate_ratio_calculate.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ duplicate_score.csv
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ duplicate_score_distribute_plot.png
â”‚   â”‚   â”œâ”€â”€ ğŸ duplicate_statistic.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ duplicate_statistic.txt
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ relationship_comment_and_post_karma.png
â”‚   â”‚   â””â”€â”€ ğŸ–¼ï¸ relationship_post_and_comment_duplicate_score.png
â”‚   â””â”€â”€ ğŸ“ viewUserDuplicates
â”‚       â”œâ”€â”€ ğŸ–¼ï¸ result.png
â”‚       â””â”€â”€ ğŸ viewUserDuplicates.py
â”œâ”€â”€ ğŸ“ database
â”‚   â”œâ”€â”€ ğŸ“ data
â”‚   â”œâ”€â”€ ğŸ“ image
â”‚   â”‚   â”œâ”€â”€ ğŸ–¼ï¸ ERD.png
â”‚   â”‚   â””â”€â”€ ğŸ–¼ï¸ diagram.png
â”‚   â”œâ”€â”€ ğŸ“ new_data
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ data_mixer.py
â”‚   â”œâ”€â”€ ğŸ database_access.py
â”‚   â”œâ”€â”€ ğŸ database_fetcher.py
â”‚   â””â”€â”€ ğŸ“„ query.sql
â”œâ”€â”€ ğŸ“ get_data
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ constants.py
â”‚   â”œâ”€â”€ ğŸ reddit_crawler.py
â”‚   â””â”€â”€ ğŸ reddit_crawler_to_sqlite.py
â”œâ”€â”€ ğŸ“ utils
â”‚   â””â”€â”€ ğŸ __init__.py
â”œâ”€â”€ âš™ï¸ .gitignore
â”œâ”€â”€ ğŸ“˜ ContentLAB_4_5.docx
â”œâ”€â”€ ğŸ“ README.md
â”œâ”€â”€ ğŸ auth.py
â””â”€â”€ ğŸ“„ requirements.txt
```

---


âš™ï¸ Installation:


    1ï¸âƒ£ Clone repository: 

                        - git clone https://github.com/yourusername/reddit-spam-detector.git

                        - cd reddit-spam-detector

    2ï¸âƒ£ Create virtual environment (optional):

                        - python -m venv venv

                        - source venv/bin/activate      # Windows: venv\Scripts\activate

    3ï¸âƒ£ Install dependencies:

                        - pip install -r requirements.txt

    4ï¸âƒ£ Configure Reddit API:
    
                        - Create config.json:
                        {
                        "client_id": "YOUR_CLIENT_ID",
                        "client_secret": "YOUR_CLIENT_SECRET",
                        "user_agent": "RedditSpamDetector/1.0"
                        }
    
    5ï¸âƒ£ Set up and connect to database (SQL-Server), run file reddit_crawler.py 

âš™ï¸ Installation Automatic:
    1ï¸âƒ£ Set up file .yml for github action. 

    2ï¸âƒ£ Get and set up Google API to access Google Drive

    3ï¸âƒ£ Use github action to run file reddit_crawler_to_sqlite.py

ğŸ¤ Contributing:

    1. Fork the repository

    2. Create a new branch (git checkout -b feature/new-feature)

    3. Commit your changes (git commit -m "Add new feature")

    4. Push and create a Pull Request


ğŸ“œ License:

    + None


ğŸ“§ Contact:

    + ğŸ‘¤ Nguyen Van Vinh

    + ğŸ“© Email: vinhvane685@gmail.com

    + ğŸ’» GitHub: @Vinhnub

    + ğŸŒ Project: Reddit Spam Detector
